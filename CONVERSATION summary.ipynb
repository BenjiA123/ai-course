{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd6f65d-c42e-44d8-a320-bae7c529d8e2",
   "metadata": {},
   "source": [
    "## Conversation Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62e4379a-3c90-4171-bc58-5782784c5665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b0b200-8847-4a39-a4fd-be05a2665c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b793b2da-2615-4740-8ab8-1612edf0b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4',\n",
    "                  seed = 365,\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c912f327-54cc-4da5-b3eb-35d07e2dbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context.\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human:\n",
    "{question}\n",
    "\n",
    "AI:\n",
    "\n",
    "'''\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153fbba9-c16c-45ea-9b5e-48964d899445",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory = ConversationSummaryMemory(llm = ChatOpenAI(),\n",
    "                                        memory_key='message_log',\n",
    "                                        return_messages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d55cb597-d9a8-456a-9e35-68a0af653827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': \"The human asks the AI for an interesting fact they probably didn't know about. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping blood to the rest of the body. Interestingly, when an octopus swims, the third heart stops beating, which is why they prefer to crawl rather than swim. The AI elaborates on the cardiovascular system of octopuses, explaining the functions of each of their three hearts and how they work together for the octopus to survive.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "432ea8b3-64be-4548-b66a-652be216cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=chat,\n",
    "                 prompt=prompt_template,\n",
    "                 memory=chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2585974-8453-42f3-970b-38f5a1d3ffab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI for an interesting fact they probably didn't know about. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping blood to the rest of the body. Interestingly, when an octopus swims, the third heart stops beating, which is why they prefer to crawl rather than swim.\n",
      "\n",
      "Human:\n",
      "Can you elaborate a bit more on this?\n",
      "\n",
      "AI:\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact they probably didn't know about. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping blood to the rest of the body. Interestingly, when an octopus swims, the third heart stops beating, which is why they prefer to crawl rather than swim.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you elaborate a bit more on this?\n",
      "AI: Absolutely! Octopuses are fascinating creatures with a unique cardiovascular system. They have three hearts, two of which are branchial hearts and one is a systemic heart. The branchial hearts are located near each of the two gills and their primary function is to pump blood through each of the two gills where the blood gets oxygenated. \n",
      "\n",
      "The systemic heart, on the other hand, pumps the oxygenated blood to the rest of the body. However, this heart stops beating when the octopus\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you elaborate a bit more on this?',\n",
       " 'message_log': \"The human asks the AI for an interesting fact they probably didn't know about. The AI shares that octopuses have three hearts, with two pumping blood to the gills and one pumping blood to the rest of the body. Interestingly, when an octopus swims, the third heart stops beating, which is why they prefer to crawl rather than swim.\",\n",
       " 'text': 'Absolutely! Octopuses are fascinating creatures with a unique cardiovascular system. They have three hearts, two of which are branchial hearts and one is a systemic heart. The branchial hearts are located near each of the two gills and their primary function is to pump blood through each of the two gills where the blood gets oxygenated. \\n\\nThe systemic heart, on the other hand, pumps the oxygenated blood to the rest of the body. However, this heart stops beating when the octopus'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are follow up questions\n",
    "\n",
    "# chain.invoke({'question':\"Can you give me an interesting fact I probably didn't know about?\"})\n",
    "chain.invoke({'question':\"Can you elaborate a bit more on this?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc3001-2e9f-44c4-bcb8-0124f71289fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6865b28-ebd6-4435-b9e2-9a3f1ab919df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8c223-6778-40d9-b146-1f6833d096ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa9a7c-4f80-4cdf-a7b7-599c2af71e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2aef03-4607-40bc-a4a7-6b5ed33090ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb555b-8602-4df5-ac2f-2c81a1d4d174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca17d23-a75f-44cd-b74a-2ba485493dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env_benji",
   "language": "python",
   "name": "langchain_env_benji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
