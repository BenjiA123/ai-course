{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1063d54a",
   "metadata": {},
   "source": [
    "# Adding Memory to a Chain (Part 1): Implementing the Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f91d3-7cef-4c67-9a9b-b43b8deb1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the line of code below to check the version of langchain in the current environment.\n",
    "# Substitute \"langchain\" with any other package name to check their version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4211bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df900c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727890ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human: \n",
    "{question}\n",
    "\n",
    "AI:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d343548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain_env_benji/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3519: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4', \n",
    "                  model_kwargs = {'seed':365},\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577021c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb1ca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Absolutely! Octopuses are fascinating creatures with a unique cardiovascular system. They have three hearts, each serving a specific purpose. Two of these hearts, known as branchial hearts, are located near each of the octopus's two gills. These branchial hearts pump blood to the gills, where it gets oxygenated.\\n\\nThe third heart, known as the systemic heart, pumps the oxygenated blood from the gills to the rest of the body. This heart actually stops beating when the oct\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'message_log':'''The AI provides an interesting fact about octopuses, stating that they have three hearts. \n",
    "Two hearts pump blood to the gills, while the third heart pumps it to the rest of the body.''', \n",
    "              'question':\"Can you elaborate a bit more on this fact?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc451d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/l8bzvy196wn95cjygzkqtsfw0000gn/T/ipykernel_98022/3865083148.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory = ConversationSummaryMemory(llm = ChatOpenAI(), memory_key = 'message_log')\n"
     ]
    }
   ],
   "source": [
    "chat_memory = ConversationSummaryMemory(llm = ChatOpenAI(), memory_key = 'message_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd23c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25358811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Can you give me an interesting fact I probably didn't know about?\",\n",
       " 'message_log': {'message_log': ''}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough.assign(\n",
    "    message_log = chat_memory.load_memory_variables\n",
    ").invoke({'question':\"Can you give me an interesting fact I probably didn't know about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3369902",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunnablePassthrough.assign(\n",
    "    first_letter = lambda x: list(x['input'])[0],\n",
    "    second_letter = lambda x: list(x['input'])[1]\n",
    ").invoke({'input':\"hi?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fe5d0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Can you give me an interesting fact I probably didn't know about?\",\n",
       " 'message_log': ''}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough.assign(\n",
    "    message_log = RunnableLambda(chat_memory.load_memory_variables) | RunnableLambda(itemgetter('message_log'))\n",
    ").invoke({'question':\"Can you give me an interesting fact I probably didn't know about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dad5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env_benji",
   "language": "python",
   "name": "langchain_env_benji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
