{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import (ConversationSummaryMemory,\n",
    "                                ConversationBufferMemory, CombinedMemory)\n",
    "\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4',\n",
    "                  seed = 365,\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context.\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Past messages:\n",
    "{message_buffer_log}\n",
    "\n",
    "Conversation summary:\n",
    "{message_summary_log}\n",
    "\n",
    "Human:\n",
    "{question}\n",
    "\n",
    "AI:\n",
    "\n",
    "'''\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/l8bzvy196wn95cjygzkqtsfw0000gn/T/ipykernel_64594/2747412759.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_buffer_memory = ConversationBufferMemory(\n",
      "/var/folders/l0/l8bzvy196wn95cjygzkqtsfw0000gn/T/ipykernel_64594/2747412759.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_summary_memory = ConversationSummaryMemory(\n"
     ]
    }
   ],
   "source": [
    "chat_buffer_memory = ConversationBufferMemory(\n",
    "    memory_key='message_buffer_log', \n",
    "    input_key='question', \n",
    "    return_messages=False)\n",
    "\n",
    "chat_summary_memory = ConversationSummaryMemory(\n",
    "    llm=ChatOpenAI(),\n",
    "    memory_key='message_summary_log',\n",
    "    input_key='question',\n",
    "    return_messages=False)\n",
    "\n",
    "chat_combined_memory = CombinedMemory(memories=[chat_buffer_memory, chat_summary_memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks the AI for an interesting fact about octopuses. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping blood to the rest of the body. The AI explains that when an octopus swims, the heart that delivers blood to the body stops beating, which is why they prefer crawling. Additionally, the AI elaborates on how the two branchial hearts and one systemic heart work together to supply oxygenated blood to the octopus's body.\n"
     ]
    }
   ],
   "source": [
    "print(chat_combined_memory.load_memory_variables({})['message_summary_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/l8bzvy196wn95cjygzkqtsfw0000gn/T/ipykernel_64594/3866033956.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_template,\n",
    "    memory=chat_combined_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Past messages:\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Sure, did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the rest of the body stops beating, which is why octopuses prefer to crawl rather than swim, as swimming exhausts them.\n",
      "\n",
      "Conversation summary:\n",
      "The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping blood to the rest of the body. Additionally, when an octopus swims, the heart that delivers blood to the body stops beating, which is why octopuses prefer crawling to swimming as it exhausts them.\n",
      "\n",
      "Human:\n",
      "Can you elaborate a bit more on this fact?\n",
      "\n",
      "AI:\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping blood to the rest of the body. Additionally, when an octopus swims, the heart that delivers blood to the body stops beating, which is why octopuses prefer crawling to swimming as it exhausts them.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you elaborate a bit more on this fact?\n",
      "AI: Absolutely! Octopuses are fascinating creatures. Their three hearts work in a unique way. The two hearts near the gills are called branchial hearts and they pump blood to the gills where it gets oxygenated. The third heart, known as the systemic heart, pumps this oxygenated blood to the rest of the body.\n",
      "\n",
      "When an octopus is at rest, all three hearts beat simultaneously. However, when it swims, the systemic heart, which is responsible for pumping blood to the body,\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you elaborate a bit more on this fact?',\n",
       " 'message_buffer_log': \"Human: Can you give me an interesting fact I probably didn't know about?\\nAI: Sure, did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the rest of the body stops beating, which is why octopuses prefer to crawl rather than swim, as swimming exhausts them.\",\n",
       " 'message_summary_log': 'The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping blood to the rest of the body. Additionally, when an octopus swims, the heart that delivers blood to the body stops beating, which is why octopuses prefer crawling to swimming as it exhausts them.',\n",
       " 'text': 'Absolutely! Octopuses are fascinating creatures. Their three hearts work in a unique way. The two hearts near the gills are called branchial hearts and they pump blood to the gills where it gets oxygenated. The third heart, known as the systemic heart, pumps this oxygenated blood to the rest of the body.\\n\\nWhen an octopus is at rest, all three hearts beat simultaneously. However, when it swims, the systemic heart, which is responsible for pumping blood to the body,'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.invoke({'question': \"Can you give me an interesting fact I probably didn't know about?\"})\n",
    "chain.invoke({'question': \"Can you elaborate a bit more on this fact?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env_benji",
   "language": "python",
   "name": "langchain_env_benji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
